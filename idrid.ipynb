{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8cdb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4681709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b6dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'datasets/B-Disease_Grading'\n",
    "data_path = '1-Original_Images'\n",
    "label_path = '2-Groundtruths'\n",
    "\n",
    "train_data_path = os.path.join(dataset_path, data_path, 'a-Train_Set')\n",
    "test_data_path = os.path.join(dataset_path, data_path, 'b-Test_Set')\n",
    "train_labels = os.path.join(dataset_path, label_path, 'a-Train_Labels.csv')\n",
    "test_labels = os.path.join(dataset_path, label_path, 'b-Test_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af9a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDRiDDataset(Dataset):\n",
    "    def __init__(self, img_dir, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx]['Image name'] + '.jpg'\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path)#.convert('RGB')\n",
    "\n",
    "        retinopathy = int(self.data.iloc[idx]['Retinopathy grade'])\n",
    "        edema = int(self.data.iloc[idx]['Risk of macular edema '])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, {'retinopathy': retinopathy, 'edema': edema}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ae733e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:12<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.64398366 0.31709325 0.10248035]\n",
      "Std: [0.11275874 0.08133845 0.03794106]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_mean_std(dataset):\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    nb_samples = 0\n",
    "\n",
    "    for images, _ in tqdm(loader):\n",
    "        batch_samples = images.size(0)  # batch size (32)\n",
    "        images = images.view(batch_samples, images.size(1), -1)  # [B, C, H*W]\n",
    "        \n",
    "        mean += images.mean(2).sum(0)  # sum of channel means\n",
    "        std += images.std(2).sum(0)    # sum of channel stds\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "\n",
    "    return mean.numpy(), std.numpy()\n",
    "\n",
    "transform_mean_std = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(448),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset_mean_std = IDRiDDataset(\n",
    "    img_dir=train_data_path,\n",
    "    csv_file=train_labels,\n",
    "    transform=transform_mean_std\n",
    ")\n",
    "\n",
    "mean, std = compute_mean_std(dataset_mean_std)\n",
    "print(f\"Mean: {mean}\\nStd: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "277d619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "train_val_dataset = IDRiDDataset(\n",
    "    img_dir=train_data_path,\n",
    "    csv_file=train_labels,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_val_dataset, [0.8, 0.2])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce23192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # input: [B, 3, 448, 448]\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)                          # [B, 32, 224, 224]\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)                          # [B, 64, 112, 112]\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)                          # [B, 128, 56, 56]\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 56 * 56, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)  # Change num_classes based on your task\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cac326f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(pd.read_csv(train_labels)['Retinopathy grade'].unique())\n",
    "cnn_model = SimpleCNN(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, device, epochs=10):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # === Training Phase ===\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            targets = labels['retinopathy'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += targets.size(0)\n",
    "            train_correct += (predicted == targets).sum().item()\n",
    "\n",
    "        avg_train_loss = train_loss / train_total\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "\n",
    "        # === Validation Phase ===\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                targets = labels['retinopathy'].to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += (predicted == targets).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / val_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Print metrics after each epoch\n",
    "        epochs_length = len(str(epochs))\n",
    "        print(f\"Epoch {epoch+1:0{epochs_length}}/{epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train Loss: 1.4575 | Train Acc: 32.93% | Val Loss: 1.4985 | Val Acc: 32.93%\n",
      "Epoch 2/25 | Train Loss: 1.4284 | Train Acc: 36.86% | Val Loss: 1.4939 | Val Acc: 32.93%\n",
      "Epoch 3/25 | Train Loss: 1.4259 | Train Acc: 32.63% | Val Loss: 1.4923 | Val Acc: 40.24%\n",
      "Epoch 4/25 | Train Loss: 1.4235 | Train Acc: 40.79% | Val Loss: 1.4826 | Val Acc: 42.68%\n",
      "Epoch 5/25 | Train Loss: 1.4072 | Train Acc: 43.81% | Val Loss: 1.4665 | Val Acc: 41.46%\n",
      "Epoch 6/25 | Train Loss: 1.3965 | Train Acc: 41.99% | Val Loss: 1.4685 | Val Acc: 41.46%\n",
      "Epoch 7/25 | Train Loss: 1.3740 | Train Acc: 44.41% | Val Loss: 1.4239 | Val Acc: 41.46%\n",
      "Epoch 8/25 | Train Loss: 1.2878 | Train Acc: 50.15% | Val Loss: 1.4082 | Val Acc: 45.12%\n",
      "Epoch 9/25 | Train Loss: 1.3475 | Train Acc: 43.50% | Val Loss: 1.5617 | Val Acc: 42.68%\n",
      "Epoch 10/25 | Train Loss: 1.1313 | Train Acc: 56.80% | Val Loss: 1.5970 | Val Acc: 41.46%\n",
      "Epoch 11/25 | Train Loss: 1.0225 | Train Acc: 61.03% | Val Loss: 1.4434 | Val Acc: 42.68%\n",
      "Epoch 12/25 | Train Loss: 0.8689 | Train Acc: 67.37% | Val Loss: 2.0320 | Val Acc: 41.46%\n",
      "Epoch 13/25 | Train Loss: 0.7198 | Train Acc: 73.72% | Val Loss: 2.2100 | Val Acc: 37.80%\n",
      "Epoch 14/25 | Train Loss: 0.5175 | Train Acc: 80.36% | Val Loss: 2.2671 | Val Acc: 40.24%\n",
      "Epoch 15/25 | Train Loss: 0.4165 | Train Acc: 85.50% | Val Loss: 2.5531 | Val Acc: 41.46%\n",
      "Epoch 16/25 | Train Loss: 0.3207 | Train Acc: 88.22% | Val Loss: 4.7389 | Val Acc: 37.80%\n",
      "Epoch 17/25 | Train Loss: 0.2487 | Train Acc: 93.05% | Val Loss: 3.2794 | Val Acc: 37.80%\n",
      "Epoch 18/25 | Train Loss: 0.1487 | Train Acc: 93.96% | Val Loss: 5.3975 | Val Acc: 39.02%\n",
      "Epoch 19/25 | Train Loss: 0.1187 | Train Acc: 96.37% | Val Loss: 4.9628 | Val Acc: 40.24%\n",
      "Epoch 20/25 | Train Loss: 0.1021 | Train Acc: 96.68% | Val Loss: 4.5306 | Val Acc: 36.59%\n",
      "Epoch 21/25 | Train Loss: 0.0648 | Train Acc: 97.89% | Val Loss: 7.0975 | Val Acc: 36.59%\n",
      "Epoch 22/25 | Train Loss: 0.0546 | Train Acc: 98.19% | Val Loss: 7.0930 | Val Acc: 36.59%\n",
      "Epoch 23/25 | Train Loss: 0.0304 | Train Acc: 98.79% | Val Loss: 8.2629 | Val Acc: 34.15%\n",
      "Epoch 24/25 | Train Loss: 0.0212 | Train Acc: 99.70% | Val Loss: 7.8371 | Val Acc: 34.15%\n",
      "Epoch 25/25 | Train Loss: 0.0153 | Train Acc: 99.40% | Val Loss: 8.6700 | Val Acc: 35.37%\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_accuracies, val_losses, val_accuracies = train(cnn_model, train_loader, val_loader,\n",
    "                                                                   optimizer, criterion, device, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80fee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "# Loss plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_losses, label='Train Loss')\n",
    "plt.plot(epochs_range, val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_accuracies, label='Train Acc')\n",
    "plt.plot(epochs_range, val_accuracies, label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
